{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e    152469\n",
      "b    115967\n",
      "t    108344\n",
      "m     45639\n",
      "Name: CATEGORY, dtype: int64\n",
      "Found 37345 unique tokens.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 130, 128)          1024000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 128, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 42, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 1,122,948\n",
      "Trainable params: 1,122,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/10\n",
      "45000/45000 [==============================] - 57s 1ms/step - loss: 0.5968 - acc: 0.7680 - val_loss: 0.3857 - val_acc: 0.8578\n",
      "Epoch 2/10\n",
      "45000/45000 [==============================] - 54s 1ms/step - loss: 0.2795 - acc: 0.8949 - val_loss: 0.3856 - val_acc: 0.8634\n",
      "Epoch 3/10\n",
      "45000/45000 [==============================] - 54s 1ms/step - loss: 0.2101 - acc: 0.9200 - val_loss: 0.4230 - val_acc: 0.8625\n",
      "Epoch 4/10\n",
      "45000/45000 [==============================] - 53s 1ms/step - loss: 0.1613 - acc: 0.9384 - val_loss: 0.4969 - val_acc: 0.8559\n",
      "Epoch 5/10\n",
      "45000/45000 [==============================] - 54s 1ms/step - loss: 0.1230 - acc: 0.9527 - val_loss: 0.5675 - val_acc: 0.8527\n",
      "Epoch 6/10\n",
      "45000/45000 [==============================] - 53s 1ms/step - loss: 0.0940 - acc: 0.9633 - val_loss: 0.6308 - val_acc: 0.8469\n",
      "Epoch 7/10\n",
      "45000/45000 [==============================] - 53s 1ms/step - loss: 0.0706 - acc: 0.9730 - val_loss: 0.7215 - val_acc: 0.8485\n",
      "Epoch 8/10\n",
      "45000/45000 [==============================] - 53s 1ms/step - loss: 0.0547 - acc: 0.9785 - val_loss: 0.8010 - val_acc: 0.8471\n",
      "Epoch 9/10\n",
      "45000/45000 [==============================] - 55s 1ms/step - loss: 0.0443 - acc: 0.9821 - val_loss: 0.9123 - val_acc: 0.8404\n",
      "Epoch 10/10\n",
      "45000/45000 [==============================] - 54s 1ms/step - loss: 0.0396 - acc: 0.9844 - val_loss: 0.9286 - val_acc: 0.8463\n",
      "20000/20000 [==============================] - 7s 338us/step\n",
      "test loss: 0.9027475805222989\n",
      "test accuracy: 0.8497\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XecVOXZ//HPRXPpUnRFUBcTSwSlrQrxCcHYNRYUDUYJqIgxwZIYYzcmpjyxRn/RKCoRHwsQbGhQjIYFG5FqAwtBkaVILwusbLl+f9y7y+yyZVj27NnZ+b5fr3nNOWfOzFxzs8w1dzn3be6OiIgIQJO4AxARkYZDSUFERMooKYiISBklBRERKaOkICIiZZQURESkjJKCiIiUUVIQEZEySgoiIlKmWdwB7KrOnTt7VlZW3GHsli1bttC6deu4w2gwVB47qCzKU3mUtzvlMWfOnDXuvldN56VcUsjKymL27Nlxh7FbcnJyGDRoUNxhNBgqjx1UFuWpPMrbnfIwsyXJnKfmIxERKaOkICIiZZQURESkTMr1KYhIeisoKCA3N5f8/Py4Q6l37du3Z+HChdWek5GRQbdu3WjevHmt3kNJQURSSm5uLm3btiUrKwszizucerV582batm1b5ePuztq1a8nNzaV79+61eg81H4lISsnPz6dTp05plxCSYWZ06tRpt2pRSgoiknKUEKq2u2Wj5iMRkQbKHb75BrZtC7fmzZtQTetRnVBSEBGJUJs2bcjLy6vxvIKCHV/+27bB1q2Qnw/FxTvOycxsGmGkgZKCiEg9KioKX/Zbt5ZPAoWFO85p1gxatoS99gr3LVtCRgZs3VoAZEQan/oURESSdN111/Hggw+W7d92223cfffd5OXlcdxxx9G3b18OP/xwXnzxRdzDlz3AsmWwaBF8+CHMmwcLF8K5557FSSf147TTejBlyhj22w8OPhhWrnyViy/uy3nn9WLEiOPo3Bnc8xg58iL69+/PEUccwbPPPhvZZ1RNQURS19VXw/z5dfuavXvDX/5S6UNDhw7l6quv5mc/+xkAEydO5JVXXqVJkwwef/x5mjdvx7Jlaxg8uD9du54BGMXFsGJF+KXfqhV06hR++T/99Fi6dOlIfv42jjzySC677By++aaYyy+/lBkzZtC9e3fWrVsHwO2330779u2ZOXMmbdu2Zf369XX7mRMoKYiIJOmII/qwcuUqPvxwOcuWrSYjowPr1u3PihUF3HPPjcybN4MmTZqwatUyzL7mgAP2oUkT6NsXmlRol7nvvvt5/vnnAVi6dCmff/45q1evZuDAgWXXGHTs2BGA119/nfHjx5c9t0OHDpF9RiUFEUldVfyir0urV8OGDaEpaPt2+J//GcK4cZNYt24lp5wylI4d4cUXn6KoaDUffDCHli2bk5WVRadO+XTuHF6jYkLIycnh9ddf591336VVq1YMGjSI/Px83L3SIaVVHY+C+hRERKqwahUsWRKGhbZpA127wsiRQ3n77fG89dYkRo8ewgEHgPtG9t13b1q2bM60adNYsqT6Wao3btxIhw4daNWqFZ988gkzZ84EYMCAAUyfPp0vvvgCoKz56MQTT+Svf/1r2fOjbD6KNCmY2clm9qmZLTKz6yt5/AAze8PMPjCzHDPrFmU8IiLJ2rQJvvoK2reHHj3gwAOhSxcYMKAHeXmb6dq1K126dAHgggsuYPbs2WRnZ/PUU09x6KGHVvvaJ598MoWFhRxxxBHccsst9O/fH4C99tqLMWPGcPbZZ9OrVy9+9KMfAXDzzTezfv16jj76aHr16sW0adMi+9yRNR+ZWVPgAeAEIBeYZWaT3X1Bwml3AU+4+zgz+wHwJ2BYVDGJiCQjPx/++9/QIXzggVCx5ebDDz8st9+5c2fefffdSl+rsmsU9thjD1555ZVKzz/llFM45ZRTyh1r06YN48aNq3Huo7oQZU3hKGCRuy929+3AeODMCuccBrxRsj2tksdFROpVYSF8/nlIBN/+NjSN/nqxBiXKpNAVWJqwn1tyLNH7wDkl24OBtmbWKcKYRESqVFwcagjbt8O3vgV77BF3RPUvytFHlXWVe4X9XwF/NbMRwAxgGVBY8UlmNgoYBZCZmUlOTk6dBlrf8vLyUv4z1CWVxw4qi/IqK4/27duzefPmSN7v66/3YPPmFuyzzzagkIjeptaKioqS+uz5+fm1/juKMinkAvsl7HcDliee4O7LgbMBzKwNcI67b6z4Qu4+BhgDkJ2d7am+kLcWIy9P5bGDyqK8yspj4cKFkbSrr1oVhp7usw9069ayzl+/LiTbp5CRkUGfPn1q9R5RNh/NAg4ys+5m1gIYCkxOPMHMOptZaQw3AGMjjEdEpFIbN+4YadS1YiN3moksKbh7ITAamAosBCa6+8dm9jszO6PktEHAp2b2GZAJ/CGqeEREKrNtGyxeXPVIo3QT6RXN7j4FmFLh2K0J25OASVHGICJSlcLCMFFdlCONqpo6O9kpteubrmgWkbSUONLo299Oz5FGlVFSEJG04w5Ll8LmzXDAAWEKi2TsytTZycfiXHvttfTs2ZPDDz+cCRMmALBixQoGDhxI79696dmzJ2+++SZFRUWMGDGi7Nx77713lz53MjQhnoikrNrOnL19e5jPqEWLnWsI1cycXenU2a+++ioZGRk8//zztGvXjjVr1tC/f3/OOOOMpCaxe+6555g/fz7vv/8+a9as4cgjj2TgwIE8/fTTnHTSSdx0000UFRWxdetW5s2bx7Jly/joo48A2LBhw65/+BooKYhIWiksDAmhWbNdbzLq06cPq1atYvny5axevZoOHTqw//77U1BQwI033siMGWHq7GXLlvH111+zzz771Piab731Fueffz5NmzYlMzOT73//+8yaNYsjjzySiy++mIKCAs466yx69+5NVlYWixcv5oorruC0007jxBNPrGUpVE1JQURS1q7OnL1tG3zySaghHHpo7TqWhwwZwqRJk1i5ciVDhw4F4KmnnmL16tXMmTOH5s3D1Nn5+flJvZ57xWt6g4EDBzJjxgz++c9/MmzYMK699loGDx7M+++/z9SpU3nggQeYOHEiY8fW7Uh+9SmISFqoq5FGQ4cOZfz48UyaNIkhQ4YAYSrsvffem+bNk5s6O9HAgQOZMGECRUVFrF69mhkzZnDUUUexZMkS9t57by699FIuueQS5s6dy9q1aykuLuacc87h9ttvZ+7cubX7ENVQTUFEGr3EkUaHHLJ7I4169OjB5s07T519+umnk52dTe/evWucOjvR4MGDeffdd+nVqxdmxh133ME+++zDuHHjuPPOO2nevDlt2rThiSeeYPny5Zx99tkUFxcD8Kc//an2H6QKSgq7q7AwXA65cWO4Rj7xvrJjGzbQ5+uvoWPHsBxT06bhVrpd8b66x3b3+a1bhzg6dQr3pbeWLXUFjzQa7uFq5c2boXv35EcaVWd3p85OPG5m3Hnnndx5553lHh8+fDjDhw/f6X2iqB0kSu+k4A5btlT6xV3dl3q5+y1ban6fNm1gzz3DNfR77knxHnuEXq6iovDTpago3IqLy99XdmxXH6uNPfbYOVGU3io7XnqsVSslE2lwVq2CNWvCAjmdNAdzjdInKUyYAA89VP5LfdOmmr84W7Qo+zIvu993352PVXbfvj20axcSQIL363PSM/eqE0ZeHqxbV/62du3Ox/77X3jvvfDYN99U/V4tWtScQCo7XlIVFqlrGzeG6xFK/9tKzdInKZR+Ie63H/TsWf6Lu7ov9YyM1P71a7ZTUirToUMoj12xbVv1CSTx2BdfwJw54di2bVW+5CAICaVlyx23jIzy+9UdT/ZYxeMVV1OXlJHMQvbbtoXfM61ahWajVP5vvCuqGs2UrPRJCj/+cbjJ7mnZMkwjuatTSW7bBuvXV5pAvvz4Y7IyM8M5+fnhPvG2ZUuo/yceKz2vcKflN5JXmogyMsI3R+kPgl25tW2r5FLPMjIyWLt2LZ06daoyMRQUhJFGTZum1+pp7s7atWvJyMio9WukT1KQeJX+Oq+kDv9lTg5ZtW1OKyzcOVFUvFV2vOKxrVtDc+KGDeHn5YYN4VbTgiZmO9cyd+XWrl3dJJXSZsKCglAmhYU7tiveJ3OsuDjUMEtvTZvu2nZN5+3Gz/Zu3bqRm5vL6tWrqyyKr78O3XWZmeGfs7HIz8+v8Qs/IyODbt261fo9lBQktTVrFn6tR7WYeWHhjmSR7G3x4l1LKu3alSWJPkVFYWBCsl/epcd2p8YUhyZNkkok2e6w//47+qE6daJ5x450T9hP7KPy5i0YORLGjoWnn4aTTor7gybJPfwwKf27Wb++/H3J9twDD+Q7o0dHGoqSgkh1mjXb0SFeG7uYVIpzc0NSaN48vHfpfeJ2Vfd1+ViTJqHmkZh0Ever2q7L8woKyP/qK9oUFsLChaG5ce3aahPgvS2uZ+z2P3HLPmM4f+w/4IUKiaOy+w4d6qZ9qaCg0i/yarcTjxUUVP/6rVvT6vLLdz/OGigpiERpF5NKvY5MSwEfVSwP9zBqrnRAQ8L9y+925FdPnsc5+8/itp4vwbq8cIHC2rXhy7e6UW577ll94igsrPLXe9l2TcPTmzcPCai06bBDh9ADXrqdeLzidvv20KIFK3NySP6yuNpRUhCR1GG2o7kwK6vs8EcfwfnXQZ++MG7GkTRp/VL55xUXh/GpFRJJZcmFtWvhs8/CfuIspIn9R6Vf1gcfXPmXeGXHUuSiUCUFEUlpq1fD6aeHPPHii+FC/Z00aRK+nDt0gG99K/kXLywMiaFZs7obFNDAKSmISMr65hs4+2xYuRJmzIDdGHRTuWbNoHPnOn7Rhk1JQURSkjv89Kfw1lswfjwceWTcETUOjb8uJCKN0l13weOPw29+Az/6UdzRNB5KCiKSciZPhuuug/POg1tvjTuaxkVJQURSygcfwAUXQL9+8Pe/p0Xfb71ScYpIyvj66zDSqF27MNKoVau4I2p81NEsIimhdKTR6tVhpJGmwo6GkoKINHjuMGoUvPMOTJwI2dlxR9R4qflIRBq8O+6AJ56A3/4Wzj037mgat0iTgpmdbGafmtkiM7u+ksf3N7NpZjbPzD4ws1OjjEdEUs8LL8ANN8DQoXDLLXFH0/hFlhTMrCnwAHAKcBhwvpkdVuG0m4GJ7t4HGAo8GFU8IpJ6Fi1qzYUXhuaisWNTYuqglBdlTeEoYJG7L3b37cB44MwK5zjQrmS7PbA8wnhEJIWsXAk33XQ4e+4ZRhq1bBl3ROkhyo7mrsDShP1c4OgK59wGvGZmVwCtgeMjjEdEUkRuLpx2Gmzc2Jx33oEuXeKOKH1EmRQqq+hVXFH6fOBxd7/bzAYA/2dmPd293MTnZjYKGAWQmZlJTk5OFPHWm7y8vJT/DHVJ5bGDygI++6wNN954ONu2NeWmm2azaVM+aV4kZerj7yPKpJAL7Jew342dm4cuAU4GcPd3zSwD6AysSjzJ3ccAYwCys7M91RchydFCKuWoPHZI97J46SX4xS/CxKQ5ObBmTX5al0dF9fH3EWWfwizgIDPrbmYtCB3Jkyuc8xVwHICZfQfIACpfjVtEGi13uO8+OPNMOOww+M9/oGfPuKNKT5ElBXcvBEYDU4GFhFFGH5vZ78zsjJLTrgEuNbP3gWeAEe5esYlJRBqxwkK44gq4+mo46yyYPh322SfuqNJXpFc0u/sUYEqFY7cmbC8AjokyBhFpuDZvDtNev/IK/OpX8Oc/a4K7uGmaCxGJxdKl8MMfwscfw8MPh2ksJH5KCiJS7+bMCbOdbtkCU6bAiSfGHZGUUkVNROrViy/CwIHQogW8/bYSQkOjpCAi9cId7r0XBg+GHj1g5kyNMGqIlBREJHKFhTB6NPzyl2FNhJwcjTBqqJQURCRSmzbBGWfAgw/Cr38d1kPQimkNlzqaRSQyS5eGOYwWLIAxY+DSS+OOSGqipCAikUgcYfTKK3DCCXFHJMlQ85GI1LnEEUbvvKOEkEqUFESkzrjDPfeEEUY9e4Y5jHr0iDsq2RVKCiJSJwoL4Wc/g2uuCSOMpk2DzMy4o5JdpaQgIrtt06YwZcVDD8F112mEUSpTR7OI7JavvgoJYeFCeOQRGDky7ohkdygpiEitzZ4dRhht2xZGGB2vBXVTnpqPRKRWXnghjDDKyAgjjJQQGgclBRHZJe5w992hM/mII8IcRocdFndUUleUFEQkaYWFcPnlYUGcIUM0wqgxUlIQkaSUjjB6+GG4/noYPx5atow7Kqlr6mgWkRotWRISwiefwKOPwiWXxB2RREVJQUSqNWtWGGGUnw+vvgrHHRd3RBIlNR+JSJWeew6+//3QTPTOO0oI6UBJQUR24g533RU6k3v1CnMYaYRRelBSEJFyCgrCCKNrr4Vzz4V//xv23jvuqKS+KCmISJlvvoFzzgkjjG68EZ55RiOM0o06mkUECFNVnH126Ex+4IEw46mkHyUFEWHrVjjzTHjjDQ05TXdKCiJpLi8vXIPw5pswbhwMGxZ3RBInJQWRNLZpE5x6api/6Mkn4fzz445I4hZpR7OZnWxmn5rZIjO7vpLH7zWz+SW3z8xsQ5TxiMgOGzbAiSeG4abjxyshSJBUTcHMjgHmu/sWM7sQ6Avc5+5LqnlOU+AB4AQgF5hlZpPdfUHpOe7+i4TzrwD61O5jiMiuWLcuJIQPPoBJk0J/gggkX1P4G7DVzHoBvwaWAE/U8JyjgEXuvtjdtwPjger+9M4HnkkyHhGppdWr4Qc/gI8+CmsiKCFIomT7FArd3c3sTEIN4TEzG17Dc7oCSxP2c4GjKzvRzA4AugP/ruLxUcAogMzMTHJycpIMu2HKy8tL+c9Ql1QeO0RdFuvWNeeaa3qzfHkGf/jDR7RqtZ6GXPT62yivPsoj2aSw2cxuAC4EBpY0DTWv4TlWyTGv4tyhwCR3L6rsQXcfA4wByM7O9kGDBiUVdEOVk5NDqn+GuqTy2CHKsli+PMxdtGpVuBbh2GN7RfI+dUl/G+XVR3kk23z0I+Ab4BJ3X0moBdxZw3Nygf0S9rsBy6s4dyhqOhKJzNKlYWK73NzShBB3RNJQJV1TIDQbFZnZwcCh1PwlPgs4yMy6A8sIX/w/rniSmR0CdADeTTpqEUnal1+GPoS1a+G112DAgLgjkoYs2ZrCDGAPM+sKvAFcBDxe3RPcvRAYDUwFFgIT3f1jM/udmZ2RcOr5wHh3r6ppSURq6b//DTWE9evh9deVEKRmydYUzN23mtklwP9z9zvMbH5NT3L3KcCUCsdurbB/W7LBikjyPvss1BDy88NMp3004FuSkGxNwcxsAHAB8M+SY02jCUlEdtfChaGGsH07TJumhCDJSzYpXA3cADxf0gR0IDAturBEpLY+/DAkBICcHDj88FjDkRSTVPORu08HpptZWzNr4+6LgSujDU1EdtW8eXDCCZCREZqMDj447ogk1SRVUzCzw81sHvARsMDM5phZj2hDE5FdMWtW6ENo3RqmT1dCkNpJtvnoYeCX7n6Au+8PXAM8El1YIrIr3n0Xjj8eOnQICeFb34o7IklVySaF1u5e1ofg7jlA60giEpFd8tZbYXK7vfcOCSErK+6IJJUlmxQWm9ktZpZVcrsZ+CLKwESkZjk5cNJJ0LVrSAj77VfjU0SqlWxSuBjYC3gOeL5k+6KoghKRmv3rX2GBnO7dQ0LYd9+4I5LGINnRR+vRaCORBmPKFDj7bDjkkHCl8l57xR2RNBbVJgUze4mqZzbF3c+o6jERicaLL8K554brD157DTp1ijsiaUxqqincVS9RiEhSnn0Whg6Fvn1h6lTYc8+4I5LGptqkUHLRWjlm1tfd50YXkohUZvx4uPBCOPpoeOUVaNcu7oikMUq2oznRo3UehYhU64kn4IIL4JhjQg1BCUGiUpukUNmKaiISkccegxEjwsI4U6ZAmzZxRySNWW2Swm/rPAoRqdRDD8HIkeHitJdeClNYiEQp2bmPBptZewB3f8HM9jSzs6INTSS93X8/XH45/PCH8MIL0LJl3BFJOki2pvAbd99YuuPuG4DfRBOSiNx1F1x1FQweHEYcZWTEHZGki2STQmXnJbtqm4jsgj/+Ea69Fs47DyZMgBYt4o5I0kmyX+yzzewe4AHCxWxXAHMii0okDbnD449nMW5cGGn0+OPQTD+9pJ4lW1O4AtgOTAAmAtuAn0cVlEi6Wb8ehg2DceOyGDECxo1TQpB4JDv30Rbg+ohjEUlLr74Kl1wCq1bBiBFf8Nhj3WlSm3GBInUg2dFH/zKzPRP2O5jZ1OjCEmn8Nm+Gyy6DU04Ji+PMnAnDhy9RQpBYJfvn17lkxBFQNmvq3tGEJNL4TZ8ORxwBjzwCv/41zJ4N/frFHZVI8kmh2Mz2L90xsyyqmT1VRCq3bRv88pfh6uSmTeHNN+HPf9aQU2k4ku3Kugl4y8xKJ8gbCIyKJiSRxum99+AnP4FPP4Wf/zwkA12hLA1NUjUFd38VyAY+JYxAuoYwAklEarB9O9xyC3z3u7B1a1gx7a9/VUKQhimpmoKZjQSuAroB84H+wLvAD6ILTST1ffBBqB28/36Y1O4vf4H27eOOSqRqyfYpXAUcCSxx92OBPsDqmp5kZieb2admtsjMKh3SambnmdkCM/vYzJ5OOnKRBqywEP73fyE7G1auDKul/f3vSgjS8CXbp5Dv7vlmhpnt4e6fmNkh1T3BzJoSroA+AcgFZpnZZHdfkHDOQcANwDHuvt7MNKJJUt5nn8Hw4WGI6ZAh8Le/QefOcUclkpxkawq5JdcpvAD8y8xeBJbX8JyjgEXuvtjdtwPjgTMrnHMp8EDJEFfcfVXyoYs0LMXFYWbT3r1DZ/Izz8DEiUoIklqSvaJ5cMnmbWY2DWgPvFrD07oCSxP2c4GjK5xzMICZvQ00BW4r6dQWSSlLlsBFF8G0aXDqqeH6g333jTsqkV1n7tFcbmBm5wInufvIkv1hwFHufkXCOS8DBcB5hE7sN4GeiRfKlZw3ipIhsJmZmf3Gjx8fScz1JS8vjzZaPqtMKpeHO0yZsg8PPvht3OHnP1/EqaeuxGq5PmEql0UUVB7l7U55HHvssXPcPbum86KccisX2C9hvxs7NznlAjPdvQD4wsw+BQ4CZiWe5O5jgDEA2dnZPmjQoKhirhc5OTmk+meoS6laHitWwKWXwj//CYMGhY7krKxDgUNr/ZqpWhZRUXmUVx/lEeUsK7OAg8ysu5m1AIYCkyuc8wJwLICZdSY0Jy2OMCaROjF+PPToAW+8AffdF+6zsuKOSmT3RZYU3L0QGA1MBRYCE939YzP7nZmdUXLaVGCtmS0ApgHXuvvaqGIS2V1r1oTFb84/Hw4+GObPhyuvRJPYSaMR6Yzt7j4FmFLh2K0J2w78suQm0qBNnhyai9av37E6mtY8kMZGf9IiNdi4Ea6+OqyE1qtXmKbiiCPijkokGqr0ilTj9dfh8MPhiSfgppvCpHZKCNKYKSmIVGLLFhg9Gk44AVq1gnfegd//Hlq0iDsykWgpKYhU8PbboZnogQdCs9G8eXB0xcsuRRopJQWREvn5cN118L3vQVFRuDr53nuhZcu4IxOpP+poFgHmzg1TXH/8cRhhdPfd0LZt3FGJ1D/VFCStuYfawNFHw7p1MGUKjBmjhCDpSzUFSVsbNsDFF8Pzz8PgwfDoo9CxY9xRicRLSUHS0ty5cO658NVXcM89oUO5tpPYiTQmaj6StOIODz8c1kvevh2mT4df/EIJQaSUkoKkjbw8GDYMfvrTMKvpvHkhOYjIDkoKkhYWLICjjgqrod1+e+hQ1opoIjtTn4I0ek8+CZddBm3ahHmLfvCDuCMSabhUU5BGKz8/JINhwyA7O0xzrYQgUj0lBWmUFi2CAQPCNQc33BAWwenSJe6oRBo+NR9Jo/Pcc3DRRdC0Kbz8Mpx2WtwRiaQO1RSk0di+PQwvPeccOPTQMLpICUFk16imII3C0qVhmcyZM8PymHfeqWmuRWpDSUFS3iuvhM7k7dth4sRwpbKI1I6ajyRlFRbCzTfDqadC164we7YSgsjuUk1BUtLKlXD++ZCTAyNHwv33a90DkbqgpCApJycnJISNG+Hxx2H48LgjEmk81HwkKaO4GP74RzjuOGjfHt57TwlBpK6ppiApYe3asDLalCkwdKgWwhGJipKCNHj/+U8YbrpyJTz4YJjlVFNdi0RDzUfSYLnDfffB974HTZrA22/D5ZcrIYhESUlBGqSNG8Pw0quvDkNO584Nk9qJSLSUFKTBmT8/JIAXXghXJj//PHToEHdUIukh0qRgZieb2admtsjMrq/k8RFmttrM5pfcRkYZjzRs7vDoo9C/P2zbFpbK/NWv1FwkUp8i62g2s6bAA8AJQC4wy8wmu/uCCqdOcPfRUcUhqWHLFvjZz+CJJ+CEE+Cpp2CvveKOSiT9RFlTOApY5O6L3X07MB44M8L3kxS1ZEkrjj4a/u//4Le/DXMZKSGIxCPKIaldgaUJ+7nA0ZWcd46ZDQQ+A37h7ksrnmBmo4BRAJmZmeTk5NR9tPUoLy8v5T9DXXnjjb25666+ZGRs5847F9Kv33refDPuqOKjv43yVB7l1Ud5RJkUKmsJ9gr7LwHPuPs3ZvZTYByw04KJ7j4GGAOQnZ3tgwYNquNQ61dOTg6p/hl2V0EBXHttGHJ6+OEbeOWVPenatVfcYcVOfxvlqTzKq4/yiDIp5AL7Jex3A5YnnuDuaxN2HwH+HGE80kCsWhUuRps+PQw5Pe209+na9ftxhyUiRNunMAs4yMy6m1kLYCgwOfEEM0tcNfcMYGGE8UgDMGsW9OsX5i168km4915o1qxiBVJE4hJZTcHdC81sNDAVaAqMdfePzex3wGx3nwxcaWZnAIXAOmBEVPFI/MaODSOMunSBd96B3r3jjkhEKop07iN3nwJMqXDs1oTtG4AbooxB4rd9e2gm+tvf4PjjYfx46NQp7qhEpDK6olkitWIFHHtsSAjXXQevvqqEINKQaZZUicw778CQIbBpE0yYEDqXRaRhU01B6pw7PPQQDBoErVrBzJlKCCKpQklB6lR+flgz+fLJqlQlAAAJcklEQVTLw3QVs2ZBz55xRyUiyVJSkDqzdCkMHBhGGd1yC7z0kmY3FUk16lOQOjF9elj/ID8/THV91llxRyQitaGaguwWd7j/fjjuOOjYMVyUpoQgkrqUFKTWtm6Fn/wErroKTj89JIRDD407KhHZHUoKUitffgnHHBPWPbj9dnj2WWjXLu6oRGR3qU9Bdtm//gVDh0JREbz8clhDWUQaB9UUJGnucMcdcPLJsO++MHu2EoJIY6OagiQlLw8uuQQmTgyjjMaOhTZt4o5KROqaagpSo0WLYMAAmDQp1BQmTFBCEGmsVFOQak2ZAhdcAE2ahMnsTjgh7ohEJEqqKUiliovh97+HH/4QsrJC/4ESgkjjp5qC7GTTJhg+HF54IdQSxowJE9uJSOOnpCDlfPIJDB4Mn38Of/kLXHklmMUdlYjUFyUFKfPiizBsGGRkwOuvh6mvRSS9qE9BKC6GW28NcxYdcgjMmaOEIJKuVFNIcxs2hH6DKVPgoovgwQdDTUFE0pOSQhr76KPQf7BkSUgGP/2p+g9E0p2aj9LQN9/AY49B//7hSuVp08JKaUoIIqKaQhr5/PMwvPTxx2HNGvjud+Ef/wjzGImIgJJCo7d9e7je4OGH4d//hmbN4Mwz4bLLwsI4TVRXFJEESgqN1OLF8MgjYeK6VavggAPgD38IncldusQdnYg0VEoKjUhBAbz0UqgVvPZaqAWcfnqoFZx4IjRtGneEItLQKSk0AkuW7KgVrFgB3brBb38bprru2jXu6EQklUTaomxmJ5vZp2a2yMyur+a8IWbmZpYdZTyNSWEhTJ4Mp50G3bvDH/8IffuGY198ES5GU0IQkV0VWU3BzJoCDwAnALnALDOb7O4LKpzXFrgS+E9UsTQmubnw6KNhSGlubugfuPlmGDkS9t8/7uhEJNVF2Xx0FLDI3RcDmNl44ExgQYXzbgfuAH4VYSwpragIpk4NfQUvvxyWxTzxRLj//jC1dfPmcUcoIo1FlEmhK7A0YT8XODrxBDPrA+zn7i+bmZJCBStWhBrBI4/AV19BZiZcdx1cemloMhIRqWtRJoXKro/1sgfNmgD3AiNqfCGzUcAogMzMTHJycuomwpjk5eVV+RmKi2H27A68/PK+vP12Z4qLjX791nHxxSv47nfX0Ly5s2RJ6FxuLKorj3SjsihP5VFevZSHu0dyAwYAUxP2bwBuSNhvD6wBviy55QPLgezqXrdfv36e6qZNm7bTsZUr3f/0J/cDD3QH986d3a+91v3zz+s/vvpWWXmkK5VFeSqP8nanPIDZnsR3d5Q1hVnAQWbWHVgGDAV+nJCMNgKdS/fNLAf4lbvPjjCmBqW4OMw79PDD4arjgoIwZfUf/hAmqttjj7gjFJF0E1lScPdCMxsNTAWaAmPd/WMz+x0hY02O6r0buo0bm3PXXSEZLFoEHTvC6NEwahQcemjc0YlIOov04jV3nwJMqXDs1irOHRRlLA89FMbylyqdETRxZtDKtqN4fNGiARQUwP/8D/zmNzBkiNYwEJGGIW2uaD7gADj++LDtXv6+qu2oHu/RYxm33bYfPXrs2mcQEYla2iSFU04Jt4YgJ+e/9OixX9xhiIjsRBMni4hIGSUFEREpo6QgIiJllBRERKSMkoKIiJRRUhARkTJKCiIiUkZJQUREypgnXmqbAsxsNZDqE0d3JswQK4HKYweVRXkqj/J2pzwOcPe9ajop5ZJCY2Bms91d61GXUHnsoLIoT+VRXn2Uh5qPRESkjJKCiIiUUVKIx5i4A2hgVB47qCzKU3mUF3l5qE9BRETKqKYgIiJllBTqkZntZ2bTzGyhmX1sZlfFHVPczKypmc0zs5fjjiVuZranmU0ys09K/kYGxB1TnMzsFyX/Tz4ys2fMLG3WJzSzsWa2ysw+SjjW0cz+ZWafl9x3iOK9lRTqVyFwjbt/B+gP/NzMDos5prhdBSyMO4gG4j7gVXc/FOhFGpeLmXUFrgSy3b0nYZ33ofFGVa8eB06ucOx64A13Pwh4o2S/zikp1CN3X+Huc0u2NxP+03eNN6r4mFk34DTg0bhjiZuZtQMGAo8BuPt2d98Qb1Sxawa0NLNmQCtgeczx1Bt3nwGsq3D4TGBcyfY44Kwo3ltJISZmlgX0Af4TbySx+gvwa6A47kAagAOB1cDfS5rTHjWz1nEHFRd3XwbcBXwFrAA2uvtr8UYVu0x3XwHhByawdxRvoqQQAzNrAzwLXO3um+KOJw5m9kNglbvPiTuWBqIZ0Bf4m7v3AbYQUfNAKihpLz8T6A7sC7Q2swvjjSo9KCnUMzNrTkgIT7n7c3HHE6NjgDPM7EtgPPADM3sy3pBilQvkuntpzXESIUmkq+OBL9x9tbsXAM8B3405prh9bWZdAEruV0XxJkoK9cjMjNBmvNDd74k7nji5+w3u3s3dswgdiP9297T9JejuK4GlZnZIyaHjgAUxhhS3r4D+Ztaq5P/NcaRxx3uJycDwku3hwItRvEmzKF5UqnQMMAz40Mzmlxy70d2nxBiTNBxXAE+ZWQtgMXBRzPHExt3/Y2aTgLmEUXvzSKOrm83sGWAQ0NnMcoHfAP8LTDSzSwhJ89xI3ltXNIuISCk1H4mISBklBRERKaOkICIiZZQURESkjJKCiIiUUVIQqUdmNkgzwkpDpqQgIiJllBREKmFmF5rZe2Y238weLln3Ic/M7jazuWb2hpntVXJubzObaWYfmNnzpfPcm9m3zex1M3u/5DnfKnn5NgnrJjxVcsWuSIOgpCBSgZl9B/gRcIy79waKgAuA1sBcd+8LTCdcZQrwBHCdux8BfJhw/CngAXfvRZi3Z0XJ8T7A1cBhhNlRj4n8Q4kkSdNciOzsOKAfMKvkR3xLwuRjxcCEknOeBJ4zs/bAnu4+veT4OOAfZtYW6OruzwO4ez5Ayeu95+65JfvzgSzgreg/lkjNlBREdmbAOHe/odxBs1sqnFfdHDHVNQl9k7BdhP4fSgOi5iORnb0BDDGzvaFsbdwDCP9fhpSc82PgLXffCKw3s++VHB8GTC9ZJyPXzM4qeY09zKxVvX4KkVrQLxSRCtx9gZndDLxmZk2AAuDnhIVvepjZHGAjod8BwjTGD5V86SfObjoMeNjMflfyGpHMailSlzRLqkiSzCzP3dvEHYdIlNR8JCIiZVRTEBGRMqopiIhIGSUFEREpo6QgIiJllBRERKSMkoKIiJRRUhARkTL/H8nsbFmpEZMrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''defalut LSTM'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers import LSTM, Dense, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class log(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_loss = {'batch':[], 'epoch':[]}\n",
    "        self.val_acc = {'batch':[], 'epoch':[]}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(1, len(self.val_loss[loss_type])+1)\n",
    "        plt.figure()\n",
    "        if loss_type == 'epoch':\n",
    "            # val_acc\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'r', label='val acc')\n",
    "            # val_loss\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'b', label='val loss')\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc-loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "data = pd.read_csv('input/uci-news-aggregator.csv', usecols=['TITLE', 'CATEGORY'])\n",
    "print(data.CATEGORY.value_counts())\n",
    "num_of_categories = 20000\n",
    "\n",
    "# take 20000 data of each category to have balanced data\n",
    "# and shuffle the dataset\n",
    "shuffled = data.reindex(np.random.permutation(data.index))\n",
    "e = shuffled[shuffled['CATEGORY'] == 'e'][:num_of_categories]\n",
    "b = shuffled[shuffled['CATEGORY'] == 'b'][:num_of_categories]\n",
    "t = shuffled[shuffled['CATEGORY'] == 't'][:num_of_categories]\n",
    "m = shuffled[shuffled['CATEGORY'] == 'm'][:num_of_categories]\n",
    "concated = pd.concat([e, b, t, m], ignore_index=True)\n",
    "concated = concated.reindex(np.random.permutation(concated.index))\n",
    "\n",
    "# one-hot encode the labels\n",
    "concated['LABEL'] = 0\n",
    "concated.loc[concated['CATEGORY'] == 'e', 'LABEL'] = 0\n",
    "concated.loc[concated['CATEGORY'] == 'b', 'LABEL'] = 1\n",
    "concated.loc[concated['CATEGORY'] == 't', 'LABEL'] = 2\n",
    "concated.loc[concated['CATEGORY'] == 'm', 'LABEL'] = 3\n",
    "labels = to_categorical(concated['LABEL'], num_classes=4)\n",
    "concated.drop(['CATEGORY'], axis=1)\n",
    "\n",
    "# tokenize the title data\n",
    "max_num_words = 8000\n",
    "max_sequence_length = 130\n",
    "tokenizer = Tokenizer(num_words = max_num_words)\n",
    "tokenizer.fit_on_texts(concated['TITLE'].values)\n",
    "sequences = tokenizer.texts_to_sequences(concated['TITLE'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found {} unique tokens.'.format(len(word_index)))\n",
    "data_processed = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# prepare the training and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_processed, labels, test_size=0.25, random_state=7)\n",
    "\n",
    "# define hyperparameters\n",
    "epochs = 10\n",
    "embedding_dim = 128\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "HISTORY = log()\n",
    "\n",
    "# build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_num_words, embedding_dim, input_length=data_processed.shape[1]))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(LSTM(64, activation='tanh'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=learning_rate), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.25,\n",
    "          callbacks=[HISTORY])\n",
    "\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('test loss:', scores[0])\n",
    "print('test accuracy:', scores[1])\n",
    "\n",
    "# draw the callback function\n",
    "HISTORY.loss_plot('epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e    152469\n",
      "b    115967\n",
      "t    108344\n",
      "m     45639\n",
      "Name: CATEGORY, dtype: int64\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "Found 37386 unique tokens.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 130, 128)          1024000   \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 128, 128)          49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 42, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 64)                49408     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 1,122,948\n",
      "Trainable params: 1,122,948\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 45000 samples, validate on 15000 samples\n",
      "Epoch 1/10\n",
      " 4224/45000 [=>............................] - ETA: 57s - loss: 1.3747 - acc: 0.3123"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-c829f290a8a2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    102\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m           \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m           callbacks=[HISTORY])\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\my_own_app\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mC:\\my_own_app\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\my_own_app\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\my_own_app\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\my_own_app\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''defalut LSTM'''\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers import LSTM, Dense, Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import Callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "class log(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.val_loss = {'batch':[], 'epoch':[]}\n",
    "        self.val_acc = {'batch':[], 'epoch':[]}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(1, len(self.val_loss[loss_type])+1)\n",
    "        plt.figure()\n",
    "        if loss_type == 'epoch':\n",
    "            # val_acc\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'r', label='val acc')\n",
    "            # val_loss\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'b', label='val loss')\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc-loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.grid()\n",
    "        plt.show()\n",
    "\n",
    "data = pd.read_csv('input/uci-news-aggregator.csv', usecols=['TITLE', 'CATEGORY'])\n",
    "print(data.CATEGORY.value_counts())\n",
    "num_of_categories = 20000\n",
    "\n",
    "# take 45000 data of each category to have balanced data\n",
    "# and shuffle the dataset\n",
    "shuffled = data.reindex(np.random.permutation(data.index))\n",
    "e = shuffled[shuffled['CATEGORY'] == 'e'][:num_of_categories]\n",
    "b = shuffled[shuffled['CATEGORY'] == 'b'][:num_of_categories]\n",
    "t = shuffled[shuffled['CATEGORY'] == 't'][:num_of_categories]\n",
    "m = shuffled[shuffled['CATEGORY'] == 'm'][:num_of_categories]\n",
    "concated = pd.concat([e, b, t, m], ignore_index=True)\n",
    "concated = concated.reindex(np.random.permutation(concated.index))\n",
    "\n",
    "# one-hot encode the labels\n",
    "concated['LABEL'] = 0\n",
    "concated.loc[concated['CATEGORY'] == 'e', 'LABEL'] = 0\n",
    "concated.loc[concated['CATEGORY'] == 'b', 'LABEL'] = 1\n",
    "concated.loc[concated['CATEGORY'] == 't', 'LABEL'] = 2\n",
    "concated.loc[concated['CATEGORY'] == 'm', 'LABEL'] = 3\n",
    "labels = to_categorical(concated['LABEL'], num_classes=4)\n",
    "print(labels[:10])\n",
    "concated.drop(['CATEGORY'], axis=1)\n",
    "\n",
    "# tokenize the title data\n",
    "max_num_words = 8000\n",
    "max_sequence_length = 130\n",
    "tokenizer = Tokenizer(num_words = max_num_words)\n",
    "tokenizer.fit_on_texts(concated['TITLE'].values)\n",
    "sequences = tokenizer.texts_to_sequences(concated['TITLE'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found {} unique tokens.'.format(len(word_index)))\n",
    "data_processed = pad_sequences(sequences, maxlen=max_sequence_length)\n",
    "\n",
    "# prepare the training and test data\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_processed, labels, test_size=0.25, random_state=7)\n",
    "\n",
    "# define hyperparameters\n",
    "epochs = 10\n",
    "embedding_dim = 128\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "HISTORY = log()\n",
    "\n",
    "# build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_num_words, embedding_dim, input_length=data_processed.shape[1]))\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(3))\n",
    "model.add(LSTM(64, activation='tanh'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(lr=learning_rate), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.25,\n",
    "          callbacks=[HISTORY])\n",
    "\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "\n",
    "print('test loss:', scores[0])\n",
    "print('test accuracy:', scores[1])\n",
    "\n",
    "# draw the callback function\n",
    "HISTORY.loss_plot('epoch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
